---
title: "Subir la eficiencia de pespunte creando familias de productos"
author: "Luis Espinosa Bouvy - espinosabouvy@gmail.com"
date: "4 de noviembre de 2016"
output:

  html_document:
    keep_md: yes
---
.  

```{r Leer_datos, include=FALSE, cache=FALSE}
#  pdf_document: default

     library(dplyr)
     library(ggplot2)
     library(gtools)
     library(cluster)
     library(gridExtra)
     library(tidyr)
     library(knitr)
     library(plotly)

     dptosUsar = c("CONTRAFUE-CASCO","CORTE","CORTE Y PREPARA","CU?A","ENSAMBLES",
                   "FORRADOS","MANUALIDADES","PLANTA","SUELA","FAMILIA", "SIN DEPARTAMENTO")
     
     clas.tiempos <- c("factor", #linea
                       "factor", #estilo
                       "integer", #pares
                       "factor", #fampespunte
                       "factor", #fammontado
                       "factor", #depto
                       "character", #funcion
                       "numeric", #tiempo
                       "numeric", #personas
                       "numeric") #meta
     
     #ya no se necestia, pues los tiempos son solo de estilos habilitados
     a <- read.csv("habilita.csv")%>%
          arrange(estilo, desc(colecc))%>%
          select("ESTILO" = estilo, "COLECC" = colecc, "LINEA" = linea)
     a$dup <- !duplicated(a$ESTILO, nmax = 1)
     hab <- a%>%filter(dup == TRUE)
     hab$estilo.fake <- as.factor(seq(1:dim(hab)[1]))
     
     tbtiempos <- tbl_df(read.csv("tiempos.csv", colClasses = clas.tiempos,
                                  stringsAsFactors = F))
     
     #sin filtrar deptos
     datos <- tbtiempos%>%
          select("ESTILO" = VCESTIL, DEPTO, FUNCION, TIEMPO, PERSONAS, META, LINEA)%>%
          filter(TIEMPO>0) %>%
          mutate("FUNCIONCOMUN" = FUNCION)
     
     #Agrega la coleccion
     tiempos.temp <<- merge(datos, hab, by = "ESTILO", all.x = T)
     
     #FUNCION COMúN - A,B,C PESPUNTADORES
     tiempos.temp$FUNCIONCOMUN[grep("A-PES|B-PES", tiempos.temp$FUNCION)] = "PESPUNTADOR"
     tiempos.temp$FUNCIONCOMUN[grep("A-PRE|B-PRE", tiempos.temp$FUNCION)] = "PRELIMINAR"
     tiempos <<- tiempos.temp%>%
          select("ESTILO" = estilo.fake, DEPTO, FUNCION, TIEMPO, PERSONAS, META,
                 LINEA.x, FUNCIONCOMUN, COLECC, LINEA.y, dup)%>%
          filter(!is.na(ESTILO))
     
```

```{r Agrupando, echo=FALSE,cache=TRUE}

     
     #elimina estilos de cantera con funcion CA-
     estilos <-  tiempos[-grep("CA-", tiempos$FUNCIONCOMUN),]
     
          #total personas por estilo
          totpers <- estilos%>%
               filter(DEPTO %in% "FAMILIA")%>%
               select(ESTILO, PERSONAS)%>%
               group_by(ESTILO)%>%
               summarise("TOT.PERSONAS" = sum(PERSONAS))
          
          critico <- estilos%>%
               filter(DEPTO %in% "FAMILIA")%>%
               select(ESTILO, COLECC, FUNCIONCOMUN, PERSONAS)%>%
               group_by(ESTILO, COLECC, FUNCIONCOMUN)%>%
               summarise(PERSONAS = sum(PERSONAS))
```
  
  
####RESUMEN
Crear familias de productos que tengan tiempos de proceso similar en el pespunte, es decir, una necesidad de personal especializado con la menor desviación posible entre un producto y otro, genera estabilidad en la producción, una menor diferencia entre las capacidades de producción diaria y mayores eficiencias en el balanceo del trabajo.  

Si conocemos los tiempos de proceso de cada modelo que vamos a producir y los conocimientos que debe tener la persona que debe realizar cada operacion (su especialización), podemos agrupar modelos para que las diferencias en el tiempo requerido para producirlos sea la menor posible.  Eso es lo que se busca con este análisis.  

Al final del artículo se puede encontrar la agrupación final de los modelos que usaron para este ejercicio.  


#### CONCEPTOS GENERALES
Para aclarar algunos conceptos que encontraremos más adelante en este artículo explicaremos algunos de ellos.

1. Cada producto requiere, por ejemplo, que un pespuntador-A (experto) realice ciertas costuras para el armado del zapato, dichas costuras requieren un tiempo y dicho tiempo es diferente para cada modelo, lo mismo pasa para las preliminares, los doblilladores o rebajadores.  Esto hace que necesitemos diferente cantidad de personas de cada puesto para producir diferentes modelos.

2. Cuando queremos saber cuál es nuestra necesidad de personal, lo que normalmente hacemos, es multiplicar el tiempo que se debe invertir en cada par, lo multiplicamos por los pares que debemos producir (o proyectamos producir) y eso lo dividimos entre tiempo que tenemos disponible cada día y con eso sabemos cuantas personas necesitamos.

Por ejemplo:

|Pares vendidos|Tiempo Pespuntador-A|Tiempo total|Horas Trabajo|Personas   |
|--------------|--------------------|------------|-------------|-----------|
|1000 pares    | 55 segundos/ par   |55000 seg.  |  8 hrs      | 1.9 pers  |  

Es decir, necesitamos 2 pespuntadores-A para producir 1000 pares por día.

Pero, que pasa cuando debemos producir 200 pares de estilo 2, que requiere 35 segundos por par de un pespuntador-A, 144 pares del estilo 2, que requiere 16 seg/par de un pesuntador-A, etc. Y además, tenemos pespuntadores-A,B y C, preliminares A,B,C, rebajadores, doblilladores, cortadores, etc.  El cálculo se complica mucho más, como podemos ver en la siguiente gráfica que representa las diferencias entre las necesidades de personal de los modelos de este ejercicio.  

```{r desvest, echo=FALSE, results="asis"}
     sd.plot <<- tiempos%>%
          filter(DEPTO == "FAMILIA" & FUNCIONCOMUN %in% c("PESPUNTADOR","PRELIMINAR",
                                                      "C-PESPUNTADOR","C-PRELIMINAR",
                                                      "DOBLILLADOR"))
     g <- ggplot(data = sd.plot,aes(FUNCIONCOMUN,PERSONAS)) + geom_boxplot(fill = "wheat") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10)) + 
          xlab("Puestos") + 
          ylab("Cantidad de personal requerido") + 
          ggtitle("Personal necesario para producir 100 pares por hora")
     
     x <- list(title = "PUESTO")
     y <- list(title = "PERSONAS")
     #gp <- ggplotly(g)     
     gp <- plot_ly(data = sd.plot, x=~FUNCIONCOMUN, y=~PERSONAS, type = "box")%>%
                   layout(xaxis = x)
     gp
     
```

La gráfica muestra como están distribuidas las necesidades de cada tipo de operario, por ejemplo, los C-Preliminar:

```{r, echo=FALSE}
quantile(sd.plot[sd.plot$FUNCIONCOMUN == "C-PRELIMINAR",]$PERSONAS)

     #familias a crear
     familias <- 6
     
```

Esto quiere decir, y lo podemos ver en la gráfica, que el 50% de los estilos requieren `r quantile(sd.plot[sd.plot$FUNCIONCOMUN == "C-PRELIMINAR",]$PERSONAS,0.5)` personas o menos, el 75% requieren `r quantile(sd.plot[sd.plot$FUNCIONCOMUN =="C-PRELIMINAR",]$PERSONAS,0.75)` o menos, es decir, la gráfica, nos muestra, que tan diferente es la cantidad de gente necesaria para producir la misma cantidad de pares de cada uno.

Como otro ejemplo, podemos ver que los **pespuntadores** requeridos para producir los modelos de nuestro análisis tiene una media de **`r round(mean(sd.plot[sd.plot$FUNCIONCOMUN == "PESPUNTADOR",]$PERSONAS),2)`** y  con un rango de **`r round(range(sd.plot[sd.plot$FUNCIONCOMUN == "PESPUNTADOR",]$PERSONAS),2)`** pespuntadores para producir la misma cantidad de pares para diferentes estilos y una desviación en las   necesidades de **`r round(sd(sd.plot[sd.plot$FUNCIONCOMUN == "PESPUNTADOR",]$PERSONAS),2)`**. *Es decir, tenemos un promedio de 5 pespuntadores, pero podemos llegar a necesitar, desde 1 hasta 26, no parece fácil de administrar.*

3. La desviación estandar en este caso la vamos a definir como la variacion en la necesidad de personal requerido para producir la misma cantidad de pares de diferentes modelos.  

Por ejemplo:  

Los doblilladores tiene una desviación estandar de `r round(sd(sd.plot[sd.plot$FUNCIONCOMUN == "DOBLILLADOR",5]),2)` y para los preliminares de `r round(sd(sd.plot[sd.plot$FUNCIONCOMUN == "PRELIMINAR",5]),2)`. Esto quiere decir que para producir la misma cantidad de pares de un estilo a otro, la cantidad de doblilladores que se necesitan cambia mucho menos, que cuando hablamos de preliminares, la variación en la necesidad de preliminares es mayor.  Como podemos ver en la gráfica siguiente:  
```{r, echo=FALSE}
prel <- sd.plot%>%filter(FUNCIONCOMUN=="PRELIMINAR" | FUNCIONCOMUN == "DOBLILLADOR")
ggplot(data = prel, aes(x=PERSONAS)) + geom_histogram(binwidth = 1, fill = "orange", colour = "black") + facet_wrap(~FUNCIONCOMUN) + ylab("Cantidad de modelos") +
     xlab("Personas necesarias")

```

Para los doblilladores, encontramos más de 80 modelos que requieren 1 doblillador, casi 50 modelos que requieren 2.  Pero al ver los preliminares, encontramos una menor  cantidad de modelos que requieren una misma cantidad de preliminares, es decir, su variación es mayor (mayor desviación estandar).  

#### TRANSFORMACION Y SIMPLIFICACIÓN
Realizaremos agrupaciones de funciones y descartaremos el uso de algunas otras en este análisis para que sea lo más utilizable en la realidad y sobre todo para que sea interpretable cuando realicemos gráficos y poder ver los resultados de forma sencilla.

1. Los pespuntadores A (expertos) y pespuntadores B (completos), así como prelimares A y B, serán consideradas únicamente como PESPUNTADORES y PRELIMINARES, asumiendo que los tipo B, pueden realizar las operaciones de tipo A, pero con una menor velocidad.  

2. Las funciones que tengan una desviación estandar (dispersión en la necesidad) menor a UNA persona, también serán descartados para el análisis individual, pues simplifica el análisis y la diferencia en la necesidad de estas funciones entre un grupo y otro no ser significativa para decidir si un modelo entra en un grupo o en otro.

En la siguiente gráfica podemos ver las funciones que serán descartadas para el análisis.  

```{r, echo=FALSE}
sds <- sd.plot%>%
     filter(FUNCION %in% c("A-PESPUNTADOR","B-PESPUNTADOR","A-PRELIMINAR",
                           "B-PRELIMINAR", "C-PESPUNTADOR","C-PRELIMINAR",
                           "DOBLILLADOR")) %>%
     group_by(FUNCION)%>%summarize("Dispersion" = sd(PERSONAS))
ggplot(data = sds, aes(x= FUNCION, y=Dispersion)) + geom_point(size = 2, col = "NAVY") + geom_hline(yintercept = 1, col = "RED", lwd = 1) + ylab("Desviación estandar")+
     theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

*Las funciones que no serán tomadas en cuenta en nuestro análisis son aquellas por debajo de la línea roja, que representan una desviación estandar igual a 1*  


3. La última consideración del análisis es agrupar el total de personas, sin tomar en cuenta la funcion o el grado de especialización como un solo valor.  Con esto se busca que la cantidad de personas necesarias, aún si no son críticas, influya de manera importante en la cantidad de pares que pueden ser producidos, al tomar en cuenta el total de personas estamos incluyendo las funciones tipo C, no críticas, pero que son operaciones que no pueden dejar de hacerse, como limpiar, quemar hebras, armar hebillas,
etc, y al mismo tiempo incluimos, pero con un menor "peso" todas aquellas funciones que descartamos anteriormente.  

Por lo tanto buscaremos agrupar los modelos que, al agruparlos en una familia de productos, minimicen la dispersión en la necesidad de los 3 grupos que definimos:  

*  **PESPUNTADOR** (todos los pespuntadores A y B)  
*  **PRELIMINAR** (todos los preliminares A y B)  
*  **TOTAL PERSONAS** (total de personas de todas la funciones)  


#### ANALISIS Y TRANFORMACION DE DATOS  

Utilizando un **analisis de clusters** incluyendo las 3 variables (pespuntadores, preliminares y total de personas), podemos definir un número de familias que agrupen una cantidad significativa de modelos.  Este análisis agrupa los modelos midiendo las distancias entre cada uno de ellos y creando un árbol que las relaciona, más adelante en el artículo se explicará con más detalle la forma en que se realiza el agrupamiento final de modelos.  

Como se puede ver en la siguiente gráfica, generar **`r familias`** familias parece una opción razonable, pues a partir del nivel marcado con la línea roja, los modelos empiezan a agruparse en grupos cada vez más pequeños y generando mayor cantidad de familias.  

```{r hclustering, echo=FALSE, warning=FALSE}
     

     #agrupando modelos con k mean y clusters y dandole más valor a pespuntadores
     #que a preliminares 2:1
     
     a <- spread(critico, FUNCIONCOMUN, PERSONAS)
     a1 <- merge(a, totpers, by= "ESTILO")
     a1$id = seq(1:nrow(a))
     p.clust <<- a1%>%
          mutate("PESP.POND" = PESPUNTADOR * 2)%>%
          select(id, ESTILO, COLECC, PESPUNTADOR, PESP.POND, PRELIMINAR, TOT.PERSONAS)
     
     Promedio.total <- sapply(p.clust[4:7], function(x) round(mean(x),2))
     Desviacion.total <-sapply(p.clust[4:7], function(x) round(sd(x),2))
     
     #kmeans analisis
     set.seed(0)
     k <<- kmeans(p.clust%>%select(PESPUNTADOR, PRELIMINAR, TOT.PERSONAS),
                  familias, nstart = 10, iter.max = 100)
     
          #por medio de hclust
     Pesp.Prel.Tot <- dist(p.clust%>%select(PESPUNTADOR, PRELIMINAR, TOT.PERSONAS))
     clusters <- hclust(Pesp.Prel.Tot,method = "complete")
     
      #print dendogram
     plot(clusters, axes = T, main = "Cluster de agrupamiento", 
          xlab = "Modelos", ylab = "Altura")
     abline(h = 22, col="red")
     famcluster <- cutree(clusters, k = familias)
     
     p.clust$FAMh <- famcluster
     p.clust <<- p.clust

     
```


Después de utilizar el método de clusters para visualizar como se relacionan los modelos por la cantidad de pespuntadores, preliminares y el total de personas necesarias utilizaremos la metología de clusters K-mean, que genera un "centro" o punto común para un grupo de modelos basandose en la cantidad de personas necesarias para producir cada modelo.

Para explicar un poco como es que se realiza esta agrupación se puede ver la siguiente gráfica:

```{r, echo=FALSE, fig.height=3, fig.width=6}

gr <- data.frame(x=c(4,4,5,6,9,11),y = c(2,3,3,4,5,9),z= c(1,1,1,1,2,2))
centers <- data.frame(x=c(4.75, 10),y = c(3,7))
graf1 <- ggplot(data = gr, aes(y=y, x=x, col=factor(z)))+ geom_point() + theme(legend.position="none") + ylab("Cantidad de preliminares") + 
     xlab("Cantidad de pespuntadores") + 
     ggtitle("Pespuntadores vs Preliminares") +
     geom_point(data = centers, aes(y=y,x=x), col= "black", pch = 3, size = 4)

gr <- data.frame(x=c(4,4,5,6,9,11),y = c(2,3,3,4,5,9),z= c(1,1,1,2,2,3))
centers <- data.frame(x=c(4.3, 7.5 , 11),y = c(2.6, 4.5 ,9))
graf2 <- ggplot(data = gr, aes(y=y, x=x, col=factor(z)))+ geom_point() + theme(legend.position="none") + ylab("Cantidad de preliminares") + 
     xlab("Cantidad de pespuntadores") + 
     ggtitle("Pespuntadores vs Preliminares")+
     geom_point(data = centers, aes(y=y,x=x), col= "black", pch = 3, size = 4)

grid.arrange(graf1, graf2, nrow = 1, ncol = 2)
```

En la gráfica izquierda vemos estilos que se agrupan en 2 familias (rojos y azules), donde la cruz representa el "centro" o promedio de cada grupo de puntos.Y en la gráfica derecha, el mismo ejercio, pero creando 3 familias de productos, basandose en agrupar aquellos modelos que generen la menor desviación en la necesidad de cada función.  

Como se puede ver, los resultados son diferentes y las desviaciones entre los puntos con su centro esperaríamos que bajen al crear mayor cantidad de grupos, para definir este número de manera simple e interpretable se utilizó el **Cluster de Agrupamiento**.   

El ejemplo anterior representa, de forma simplificada como será realizado el análisis, pero utilizando la cantidad de pespuntadores, preliminares y el total de personas necesarias para cada estilo.  Al ver ejemplo, nos damos cuenta que podemos definir la cantidad de familias que sean necesarias, aunque al considerar gastos de supervisión, espacio y logística que requiere tener un mayor número de familias, la decisión no involucra únicamente bajar al mínimo la desviación en la necesidad de personas.  

Por supuesto que en este tipo de  análisis se pueden agregar variables como espacio, costo por familia, costo de balanceo del trabajo, pero la intención de este artículo es demostrar lo que puede lograrse utilizando de forma profesional la información que tenemos a la mano para tomar las mejores decisiones.  

El agrupamiento comienza definiendo **`r familias`** clusters, en este caso **`r familias`** familias para agrupar todos los modelos. Y se puede ver en la siguiente gráfica la forma en que quedan agrupados los modelos.  

```{r kmeans.plot, echo=FALSE, warning = F,error=F}
     #plot
     # suppressWarnings(
     # clusplot(p.clust, k$cluster, main = "Agrupacion de estilos en familias",
     #          color = T, labels = 4, lines = 0, xlab = "", 
     #          ylab = "", span = FALSE, verbose = F, shade = T, stand = F, sub=""))
     p.clust$FAMILIA <- k$cluster

     #ver asignaciones en pespuntador vs preliminar
     plot1 <- ggplot(data = p.clust, aes(PESPUNTADOR, PRELIMINAR)) + 
          geom_point(aes(colour = factor(FAMILIA), size = TOT.PERSONAS), alpha= 0.5)+
          ggtitle("Pespuntadores vs Preliminares vs Total de Personas")+
          theme(legend.title=element_blank())
     plot1
     
```

Los gráficos representan el agrupamiento final de los estilos, representando en un color diferente cada familia, tomando en cuenta la relación entre la cantidad de pespuntadores, preliminares y total de personas necesarias.  

```{r final, echo=FALSE, warning = F,error=F}

     #convertir columnas en funcion comun
     plot.clust <<- gather(p.clust, "FUNCIONCOMUN", "PERSONAS",c(PRELIMINAR, PESPUNTADOR, TOT.PERSONAS))
     
     ##revisar visualmente la asignacion
     plot2 <- ggplot(data = plot.clust, aes(ESTILO, PERSONAS)) +
          geom_point(aes(colour = factor(FAMILIA)), alpha = 0.5, size = 3) +
          facet_grid(FUNCIONCOMUN~., scales = "free") +
          theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 4),
                strip.text.y = element_text(size = 10),
                panel.grid.major = element_line(colour = "darkgrey",
                                                linetype = "dotted"))+
          theme(legend.title=element_blank())
    plot2
     
```

En este gráfico se puede ver la cantidad de *PESPUNTADORES, PRELIMINARES y TOTAL DE PERSONAS* que se requieren para cada estilo, identificados por las familias anterioremente creadadas por medio de clusters. Y el tamaño de cada uno de los puntos representa la cantidad total de personas requeridas, el eje horizontal la cantidad de pespuntadores y el vertical la cantidad de preliminares para producir 100 pares por hora.  
De esta forma podemos ver gráficamente que los modelos con cantidad de pespuntadores similar quedan agrupados, excepto cuando la diferencia en el total de personas cambia de manera notable.  

#RESULTADO

Al iniciar el análisis revisamos que el promedio de pespuntadores para producir 100 pares por hora incluyendo todos los modelos en una solo familia era `r round(mean(sd.plot[sd.plot$FUNCIONCOMUN == "PESPUNTADOR",]$PERSONAS),2)`, con una desviación estandar de `r round(sd(sd.plot[sd.plot$FUNCIONCOMUN == "PESPUNTADOR",]$PERSONAS),2)`. Como podemos ver en la sigueinte tabla de promedios y desviaciones para los grupos que generamos. 
```{r}
     Promedio.total
     Desviacion.total
```


Después de este ánalisis se definieron `r familias` familias bien estandarizadas, con promedios de personal requerido bien diferenciado y deviaciones estandar menores, como se puede ver en las tablas finales.

Esto permite:

*  Bajar la cantidad de personal, (el balanceo tendra una eficencia real mayor).  
*  Menor cantidad de movimientos internos y entre familias.
*  Realizar una programación más cercana a la realidad, sin la necesidad de utilizar los tiempos especificos de cada modelo, pues la capacidad de producción para cada uno es similar.  
*  Dar a los cliente una fecha de entrega más real, pues la diferencia de producción diaria en cada familia tiene menor diferencia.
*  El personal sabe con mayor facilidad cuantos pares debe de producir hora con hora, pues la diferencia entre modelos es menor.

El paso siguiente a este análisis debe incluir la demanda o en su defecto el pronóstico de la demanda de cada modelo para obtener las plantillas de personal requerido para satisfacer las necesidades del cliente.

Posteriormente, comparando contra la plantilla actual de personal, podemos calcular las necesidades de reclutamiento y capacitación.  Del mismo modo, nuestra capacidad futura de producción o en su defecto nuestra capacidad sobrante.  

Para cada familia, la cantidad de **PESPUNTADORES** y su desviación la podemos ver en la siguiente tabla:  
```{r resul_pespuntadores, echo=FALSE}


     avgpesp <- plot.clust%>%
          filter(FUNCIONCOMUN == "PESPUNTADOR")%>%
          group_by(FAMILIA)%>%
          summarise("Promedio de pespuntadores" = round(mean(PERSONAS),0), 
                    "Desviacion std" = round(sd(PERSONAS),2))

     kable(avgpesp, format = "markdown", padding = 2)

```

Para cada familia, la cantidad de **PRELIMINARES** y su desviación la podemos ver en la siguiente tabla:  
```{r resul_preliminares, echo=FALSE}
     avgprel <- plot.clust%>%
          filter(FUNCIONCOMUN == "PRELIMINAR")%>%
          group_by(FAMILIA)%>%
          summarise("Promedio de preliminares" = round(mean(PERSONAS),0), 
                    "Desviación std" = round(sd(PERSONAS),2))

     kable(avgprel, format = "markdown")
     
```

Para cada familia, la cantidad de **TOTAL DE PERSONAS** y su desviación la podemos ver en la siguiente tabla:  
```{r resul_total_pers, echo=FALSE}
     avgprel <- plot.clust%>%
          group_by(FAMILIA)%>%
          summarise("Promedio de personas total" = round(mean(PERSONAS),0), 
                    "Desviación std" = round(sd(PERSONAS),2))

     kable(avgprel, format = "markdown")
     
```




